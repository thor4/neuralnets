{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+CEqVUk5XQwPuQLEiOLmg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thor4/neuralnets/blob/master/projects/state_farm/state_farm_task-step_3-generate_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State Farm Pre-employment Assessment\n",
        "### *Model-based supervised learning binary classification task*\n",
        "Your work will be evaluated in the following areas:\n",
        "- The appropriateness of the steps you took\n",
        "- The complexity of your models\n",
        "- The performance of each model on the test set (using AUC)\n",
        "- The organization and readability of your code\n",
        "- The write-up comparing the models\n",
        "---"
      ],
      "metadata": {
        "id": "3I9U6tnpuecf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Generate predictions\n",
        "Create predictions on the data in test.csv using each of your trained models. The predictions should be the class probabilities for belonging to the positive class (labeled '1').  \n",
        " \n",
        "Be sure to output a prediction for each of the rows in the test dataset (10K rows). Save the results of each of your models in a separate CSV file.  Title the two files 'glmresults.csv' and 'nonglmresults.csv'. Each file should have a single column representing the predicted probabilities for its respective model. Please do not include a header label or index column.\n",
        "\n",
        "We will begin by importing relevant libraries."
      ],
      "metadata": {
        "id": "FKKVf2XCvo5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zct-rkSSud0m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer, QuantileTransformer, LabelEncoder\n",
        "import joblib\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the saved models from the GitHub repository."
      ],
      "metadata": {
        "id": "bvl1wLl1Ul5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/thor4/neuralnets/master/projects/state_farm/models/logistic_regression_model.pkl\n",
        "!wget https://raw.githubusercontent.com/thor4/neuralnets/master/projects/state_farm/models/gb_model.pkl"
      ],
      "metadata": {
        "id": "R98SybX6Uo6H",
        "outputId": "8159a9d9-af46-441b-c8f3-7b2526b6b576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 02:04:29--  https://raw.githubusercontent.com/thor4/neuralnets/master/projects/state_farm/models/logistic_regression_model.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2191 (2.1K) [application/octet-stream]\n",
            "Saving to: ‘logistic_regression_model.pkl’\n",
            "\n",
            "\r          logistic_   0%[                    ]       0  --.-KB/s               \rlogistic_regression 100%[===================>]   2.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-21 02:04:29 (31.3 MB/s) - ‘logistic_regression_model.pkl’ saved [2191/2191]\n",
            "\n",
            "--2023-03-21 02:04:29--  https://raw.githubusercontent.com/thor4/neuralnets/master/projects/state_farm/models/gb_model.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176990 (173K) [application/octet-stream]\n",
            "Saving to: ‘gb_model.pkl’\n",
            "\n",
            "gb_model.pkl        100%[===================>] 172.84K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-03-21 02:04:29 (9.27 MB/s) - ‘gb_model.pkl’ saved [176990/176990]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use the pandas library to load our CSV data and joblib to load our models."
      ],
      "metadata": {
        "id": "gHKnysvV1TZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"exercise_40_test.csv\")\n",
        "logistic_regression = joblib.load('logistic_regression_model.pkl')\n",
        "gb = joblib.load('gb_model.pkl')"
      ],
      "metadata": {
        "id": "lsLMUhbm1Z2Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "ly3yQCem28eQ",
        "outputId": "49fcb3ab-db03-454a-a722-954825479055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         x1         x2         x3        x4        x5        x6       x7  \\\n",
              "0  4.747627  20.509439  Wednesday  2.299105 -1.815777 -0.752166  0.0098%   \n",
              "1  1.148654  19.301465        Fri  1.862200 -0.773707 -1.461276  0.0076%   \n",
              "2  4.986860  18.769675   Saturday  1.040845 -1.548690  2.632948  -5e-04%   \n",
              "3  3.709183  18.374375    Tuesday -0.169882 -2.396549 -0.784673  -0.016%   \n",
              "4  3.801616  20.205541     Monday  2.092652 -0.732784 -0.703101  0.0186%   \n",
              "\n",
              "         x8        x9       x10  ...       x91        x92  x93       x94  \\\n",
              "0 -3.240309  0.587948 -0.260721  ...       NaN  12.542333   no  3.107683   \n",
              "1  0.443209  0.522113 -1.090886  ... -0.848567   7.213829  yes  4.276078   \n",
              "2 -1.167885  5.739275  0.222975  ...  1.143388  10.483928   no  2.090868   \n",
              "3 -2.662226  1.548050  0.210141  ...  0.693646   3.862867   no  2.643847   \n",
              "4  0.056422  2.878167 -0.457618  ... -0.834763   3.632039  yes  4.074434   \n",
              "\n",
              "        x95        x96        x97  x98  x99        x100  \n",
              "0  0.533904  12.438759   7.298306    0  NaN   93.567120  \n",
              "1       NaN  10.386987  12.527094    1  yes   98.607486  \n",
              "2 -1.780474  11.328177  11.628247    0  yes   94.578246  \n",
              "3  1.662240  10.064961  10.550014    1  NaN  100.346261  \n",
              "4       NaN   9.255766  12.716137    1  yes  102.578918  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bf182ad-1d52-45d2-93c3-d162a7e4f34c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>...</th>\n",
              "      <th>x91</th>\n",
              "      <th>x92</th>\n",
              "      <th>x93</th>\n",
              "      <th>x94</th>\n",
              "      <th>x95</th>\n",
              "      <th>x96</th>\n",
              "      <th>x97</th>\n",
              "      <th>x98</th>\n",
              "      <th>x99</th>\n",
              "      <th>x100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.747627</td>\n",
              "      <td>20.509439</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>2.299105</td>\n",
              "      <td>-1.815777</td>\n",
              "      <td>-0.752166</td>\n",
              "      <td>0.0098%</td>\n",
              "      <td>-3.240309</td>\n",
              "      <td>0.587948</td>\n",
              "      <td>-0.260721</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.542333</td>\n",
              "      <td>no</td>\n",
              "      <td>3.107683</td>\n",
              "      <td>0.533904</td>\n",
              "      <td>12.438759</td>\n",
              "      <td>7.298306</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93.567120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.148654</td>\n",
              "      <td>19.301465</td>\n",
              "      <td>Fri</td>\n",
              "      <td>1.862200</td>\n",
              "      <td>-0.773707</td>\n",
              "      <td>-1.461276</td>\n",
              "      <td>0.0076%</td>\n",
              "      <td>0.443209</td>\n",
              "      <td>0.522113</td>\n",
              "      <td>-1.090886</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.848567</td>\n",
              "      <td>7.213829</td>\n",
              "      <td>yes</td>\n",
              "      <td>4.276078</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.386987</td>\n",
              "      <td>12.527094</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>98.607486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.986860</td>\n",
              "      <td>18.769675</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1.040845</td>\n",
              "      <td>-1.548690</td>\n",
              "      <td>2.632948</td>\n",
              "      <td>-5e-04%</td>\n",
              "      <td>-1.167885</td>\n",
              "      <td>5.739275</td>\n",
              "      <td>0.222975</td>\n",
              "      <td>...</td>\n",
              "      <td>1.143388</td>\n",
              "      <td>10.483928</td>\n",
              "      <td>no</td>\n",
              "      <td>2.090868</td>\n",
              "      <td>-1.780474</td>\n",
              "      <td>11.328177</td>\n",
              "      <td>11.628247</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>94.578246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.709183</td>\n",
              "      <td>18.374375</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>-0.169882</td>\n",
              "      <td>-2.396549</td>\n",
              "      <td>-0.784673</td>\n",
              "      <td>-0.016%</td>\n",
              "      <td>-2.662226</td>\n",
              "      <td>1.548050</td>\n",
              "      <td>0.210141</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693646</td>\n",
              "      <td>3.862867</td>\n",
              "      <td>no</td>\n",
              "      <td>2.643847</td>\n",
              "      <td>1.662240</td>\n",
              "      <td>10.064961</td>\n",
              "      <td>10.550014</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.346261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.801616</td>\n",
              "      <td>20.205541</td>\n",
              "      <td>Monday</td>\n",
              "      <td>2.092652</td>\n",
              "      <td>-0.732784</td>\n",
              "      <td>-0.703101</td>\n",
              "      <td>0.0186%</td>\n",
              "      <td>0.056422</td>\n",
              "      <td>2.878167</td>\n",
              "      <td>-0.457618</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.834763</td>\n",
              "      <td>3.632039</td>\n",
              "      <td>yes</td>\n",
              "      <td>4.074434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.255766</td>\n",
              "      <td>12.716137</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>102.578918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bf182ad-1d52-45d2-93c3-d162a7e4f34c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bf182ad-1d52-45d2-93c3-d162a7e4f34c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bf182ad-1d52-45d2-93c3-d162a7e4f34c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "cBh11z0idZAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the test dataset for pre-processing."
      ],
      "metadata": {
        "id": "_VwiMCdtdxrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_data.copy()"
      ],
      "metadata": {
        "id": "2WHpvZb_diIN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop unnecessary columns"
      ],
      "metadata": {
        "id": "wcV3RRn4UozQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.drop(columns=[\"x39\", \"x99\", \"x79\", \"x28\"])"
      ],
      "metadata": {
        "id": "nfMPlZFrUeRU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert object columns to binary int64\n"
      ],
      "metadata": {
        "id": "EU2q5JQ4Us9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_features = [\"x24\", \"x31\", \"x93\"]\n",
        "for col in binary_features:\n",
        "    le = LabelEncoder()\n",
        "    test[col] = le.fit_transform(test[col].astype(str))"
      ],
      "metadata": {
        "id": "aAcIdOJMUvBz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace null values in `x33` and `x77` with most likely value based on probabilities"
      ],
      "metadata": {
        "id": "TUmDVBO-U-Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"x33\", \"x77\"]:\n",
        "    probs = test[col].value_counts(normalize=True)\n",
        "    missing = test[col].isna()\n",
        "    test.loc[missing, col] = np.random.choice(probs.index, size=len(test[missing]), p=probs.values)"
      ],
      "metadata": {
        "id": "Yz6UiUDHU82J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine duplicate days in `x3`"
      ],
      "metadata": {
        "id": "ePxMKLv8V-oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_mapping = {\n",
        "    \"Mon\": \"Monday\",\n",
        "    \"Tue\": \"Tuesday\",\n",
        "    \"Wed\": \"Wednesday\",\n",
        "    \"Thur\": \"Thursday\",\n",
        "    \"Fri\": \"Friday\",\n",
        "    \"Sat\": \"Saturday\",\n",
        "    \"Sun\": \"Sunday\"\n",
        "}\n",
        "test[\"x3\"] = test[\"x3\"].replace(day_mapping)"
      ],
      "metadata": {
        "id": "ntj_wWcfV4_5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the `x7` column to a float by removing the % sign and dividing by 100. Convert the `x19` column to a float by removing the $ sign."
      ],
      "metadata": {
        "id": "YGROjnzlNsTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['x7'] = test['x7'].str.strip('%').astype(float) / 100\n",
        "test['x19'] = test['x19'].str.strip('$').astype(float)"
      ],
      "metadata": {
        "id": "fgF_31UUKmYC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run preprocessing pipeline"
      ],
      "metadata": {
        "id": "uCETwZrId_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformers for each group of columns\n",
        "one_hot_features = [\"x33\", \"x77\", \"x3\", \"x60\", \"x65\"]\n",
        "range_based_features = [\"x58\", \"x67\", \"x71\", \"x84\"]\n",
        "quantile_transform_features = [\"x12\", \"x18\", \"x61\", \"x92\", \"x40\", \"x57\"]\n",
        "log_transform_features = [\"x14\", \"x16\", \"x21\", \"x42\", \"x45\", \"x55\", \"x70\", \"x73\", \"x75\", \"x82\", \"x89\", \"x96\"]\n",
        "\n",
        "one_hot_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"one_hot\", OneHotEncoder())\n",
        "])\n",
        "\n",
        "def custom_discretizer(X, low_quantile=0.25, high_quantile=0.75):\n",
        "    low_bound = np.quantile(X, low_quantile, axis=0)\n",
        "    high_bound = np.quantile(X, high_quantile, axis=0)\n",
        "    return np.where(X < low_bound, 0, np.where(X <= high_bound, 1, 2))\n",
        "\n",
        "range_based_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"custom_discretizer\", FunctionTransformer(custom_discretizer, validate=True)),\n",
        "    (\"one_hot\", OneHotEncoder())\n",
        "])\n",
        "\n",
        "quantile_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"quantile_transform\", QuantileTransformer(output_distribution=\"normal\"))\n",
        "])\n",
        "\n",
        "def log1p_with_positive_shift(X):\n",
        "    positive_shift = np.abs(np.min(X, axis=0)) + 1e-6\n",
        "    return np.log1p(X + positive_shift)\n",
        "\n",
        "log_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"log_transform\", FunctionTransformer(log1p_with_positive_shift, validate=True)),\n",
        "    (\"standard_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "remaining_float_features = list(set(test.select_dtypes(include=[\"float64\"]).columns) - set(range_based_features) - set(quantile_transform_features) - set(log_transform_features))\n",
        "\n",
        "float_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"standard_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Create ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"one_hot\", one_hot_transformer, one_hot_features),\n",
        "    (\"range_based\", range_based_transformer, range_based_features),\n",
        "    (\"quantile_transform\", quantile_transformer, quantile_transform_features),\n",
        "    (\"log_transform\", log_transformer, log_transform_features),\n",
        "    (\"float_transform\", float_transformer, remaining_float_features)\n",
        "])\n",
        "\n",
        "# Apply the preprocessing pipeline\n",
        "X_transformed = preprocessor.fit_transform(test)\n",
        "\n",
        "# Get the column names from the transformers\n",
        "one_hot_cols = preprocessor.named_transformers_[\"one_hot\"].named_steps[\"one_hot\"].get_feature_names_out(one_hot_features)\n",
        "range_based_categories = [\"low\", \"middle\", \"high\"]\n",
        "range_based_cols = [f\"{col}_{cat}\" for col in range_based_features for cat in range_based_categories]\n",
        "quantile_transform_cols = [f\"quantile_{col}\" for col in quantile_transform_features]\n",
        "log_transform_cols = [f\"log_{col}\" for col in log_transform_features]\n",
        "float_transform_cols = [f\"float_{col}\" for col in remaining_float_features]\n",
        "\n",
        "print(\"One-hot cols:\", len(one_hot_cols))\n",
        "print(\"Range-based cols:\", len(range_based_cols))\n",
        "print(\"Quantile transform cols:\", len(quantile_transform_cols))\n",
        "print(\"Log transform cols:\", len(log_transform_cols))\n",
        "print(\"Float transform cols:\", len(float_transform_cols))\n",
        "\n",
        "# Combine column names\n",
        "columns = (list(one_hot_cols)\n",
        "           + list(range_based_cols)\n",
        "           + quantile_transform_cols\n",
        "           + log_transform_cols\n",
        "           + float_transform_cols)\n",
        "\n",
        "print(\"Total expected columns:\", len(columns))\n",
        "print(\"Actual columns in transformed dataset:\", X_transformed.shape[1])\n",
        "\n",
        "test_transformed = pd.DataFrame(X_transformed, columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4J-NlNLUASG",
        "outputId": "ecc46c2b-c49d-4abd-aa78-803263d85bf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot cols: 82\n",
            "Range-based cols: 12\n",
            "Quantile transform cols: 6\n",
            "Log transform cols: 12\n",
            "Float transform cols: 64\n",
            "Total expected columns: 176\n",
            "Actual columns in transformed dataset: 176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transformed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqG700y9O7tU",
        "outputId": "9c678286-b3fa-4d83-da0d-a71c8926d03c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Columns: 176 entries, x33_Alabama to float_x53\n",
            "dtypes: float64(176)\n",
            "memory usage: 13.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transformed.columns[test_transformed.isnull().sum() != 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roiZtwsTPBtb",
        "outputId": "4696d3c0-fbca-4a71-f245-e5fda7bc631b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and save predictions"
      ],
      "metadata": {
        "id": "0mvT3SK9YiE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate predictions (class probabilities) for both models."
      ],
      "metadata": {
        "id": "b482ZWisXt0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_prob = logistic_regression.predict_proba(X_transformed)[:, 1]\n",
        "gb_prob = gb.predict_proba(X_transformed)[:, 1]"
      ],
      "metadata": {
        "id": "7oI6lA00XusZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the predictions in two separate CSV files."
      ],
      "metadata": {
        "id": "Khr7UsZsYBjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save logistic_regression predictions to glmresults.csv\n",
        "pd.DataFrame(logistic_regression_prob).to_csv('glmresults.csv', header=False, index=False)\n",
        "\n",
        "# Save grid_search_gb predictions to nonglmresults.csv\n",
        "pd.DataFrame(gb_prob).to_csv('nonglmresults.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "nkLE9q-hYDM9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the files for submission."
      ],
      "metadata": {
        "id": "wSOsqHqYYRhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('glmresults.csv')\n",
        "files.download('nonglmresults.csv')"
      ],
      "metadata": {
        "id": "T0bnUdPzYKHz",
        "outputId": "dd3e14f2-3730-43f3-c669-fc40603d487f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_88bc5314-42a2-4cdd-9455-9b911b381317\", \"glmresults.csv\", 198783)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_655f696a-3544-42d8-9e69-77fa9d9edd7a\", \"nonglmresults.csv\", 198423)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}