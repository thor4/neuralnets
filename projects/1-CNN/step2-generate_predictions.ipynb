{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step2-generation_predictions",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYyAcgEVulNdUsThO0Gls3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thor4/neuralnets/blob/master/projects/1-CNN/step2-generate_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHcTgWXkB-4b"
      },
      "source": [
        "# Generate predictions from model\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKux6e-YPew0"
      },
      "source": [
        "## 1: Setup the model\n",
        "This model was created using the `step1_train_vanilla_CNN_v2.ipynb` Jupyter notebook. \n",
        "Run the cell to download a zip file from OSF then extract its contents into the newly created directory: `content/18kim_range_vanilla/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpRtxiFmDo7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a585f7ad-23d4-4aee-bd89-43bb63828b47"
      },
      "source": [
        "# @title Download model\n",
        "\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping `Range model`...\")\n",
        "name = '18kim_range_vanilla'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/tycf6/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall() #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `Range model`...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOM5VyU8x80i"
      },
      "source": [
        "#### Load the model\n",
        "Next, we load the model using Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RVZI9Dexw2N",
        "outputId": "1066ea38-4fba-4f7b-ed24-030ba58790c5"
      },
      "source": [
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "tf.random.set_seed(42) #set random seed for reproducibility\n",
        "model = tf.keras.models.load_model('18kim_range_vanilla') \n",
        "model.summary() #verify architecture"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_1 (Rescaling)      (None, 160, 160, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 158, 158, 160)     1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 79, 79, 160)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 77, 77, 80)        115280    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 80)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 36, 36, 40)        28840     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 51840)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 40)                2073640   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 2,219,401\n",
            "Trainable params: 2,219,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZXJPKMezPAP"
      },
      "source": [
        "## 2: Download & load datasets to test model with\n",
        "Download the test datasets from OSF and extract the contents into the newly created directory: `content/datasets/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "CJiTI49Sz6yw",
        "outputId": "c5f37a63-f608-46c1-9e72-c78ab7edee34"
      },
      "source": [
        "# @title Download datasets\n",
        "\n",
        "print(\"Start downloading and unzipping `18 test datasets`...\")\n",
        "name = 'model2_dset1-18_cond'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/jkryf/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall(\"datasets\") #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `18 test datasets`...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4rHfgAq0nbi"
      },
      "source": [
        "Load all 18 sets and use prefetch to streamline image loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVkzI7QC2gFL",
        "cellView": "form",
        "outputId": "dd3953b4-c400-43f1-a659-795592266d15"
      },
      "source": [
        "# @title Load datasets into tensorflow\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32 \n",
        "IMG_SIZE = (160, 160) #forces a resize from 170x170 since MobileNetV2 has weights only for certain sizes\n",
        "AUTOTUNE = tf.data.AUTOTUNE #prompts the tf.data runtime to tune the value dynamically at runtime\n",
        "def model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE):\n",
        "    curr_dir = os.getcwd() \n",
        "    set1_dir = os.path.join(curr_dir, 'datasets/s1-t_0.1-c_0.3')\n",
        "    set2_dir = os.path.join(curr_dir, 'datasets/s2-t_0.1-c_0.45')\n",
        "    set3_dir = os.path.join(curr_dir, 'datasets/s3-t_0.1-c_1')\n",
        "    set4_dir = os.path.join(curr_dir, 'datasets/s4-t_0.2-c_0.3')\n",
        "    set5_dir = os.path.join(curr_dir, 'datasets/s5-t_0.2-c_0.45')\n",
        "    set6_dir = os.path.join(curr_dir, 'datasets/s6-t_0.2-c_1')\n",
        "    set7_dir = os.path.join(curr_dir, 'datasets/s7-t_0.4-c_0.3')\n",
        "    set8_dir = os.path.join(curr_dir, 'datasets/s8-t_0.4-c_0.45')\n",
        "    set9_dir = os.path.join(curr_dir, 'datasets/s9-t_0.4-c_1')\n",
        "    set10_dir = os.path.join(curr_dir, 'datasets/s10-t_0.8-c_0.3')\n",
        "    set11_dir = os.path.join(curr_dir, 'datasets/s11-t_0.8-c_0.45')\n",
        "    set12_dir = os.path.join(curr_dir, 'datasets/s12-t_0.8-c_1')\n",
        "    set13_dir = os.path.join(curr_dir, 'datasets/s13-t_1.6-c_0.3')\n",
        "    set14_dir = os.path.join(curr_dir, 'datasets/s14-t_1.6-c_0.45')\n",
        "    set15_dir = os.path.join(curr_dir, 'datasets/s15-t_1.6-c_1')\n",
        "    set16_dir = os.path.join(curr_dir, 'datasets/s16-t_3.2-c_0.3')\n",
        "    set17_dir = os.path.join(curr_dir, 'datasets/s17-t_3.2-c_0.45')\n",
        "    set18_dir = os.path.join(curr_dir, 'datasets/s18-t_3.2-c_1')\n",
        "    set1 = image_dataset_from_directory(set1_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale') #3000 images 2 classes\n",
        "    set2 = image_dataset_from_directory(set2_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set3 = image_dataset_from_directory(set3_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set4 = image_dataset_from_directory(set4_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set5 = image_dataset_from_directory(set5_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set6 = image_dataset_from_directory(set6_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set7 = image_dataset_from_directory(set7_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale') #3000 images 2 classes\n",
        "    set8 = image_dataset_from_directory(set8_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set9 = image_dataset_from_directory(set9_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set10 = image_dataset_from_directory(set10_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set11 = image_dataset_from_directory(set11_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set12 = image_dataset_from_directory(set12_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set13 = image_dataset_from_directory(set13_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale') #3000 images 2 classes\n",
        "    set14 = image_dataset_from_directory(set14_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set15 = image_dataset_from_directory(set15_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set16 = image_dataset_from_directory(set16_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set17 = image_dataset_from_directory(set17_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set18 = image_dataset_from_directory(set18_dir, shuffle=True, batch_size=BATCH_SIZE, image_size=IMG_SIZE, color_mode='grayscale')\n",
        "    set2 = set2.prefetch(buffer_size=AUTOTUNE) \n",
        "    set1 = set1.prefetch(buffer_size=AUTOTUNE) \n",
        "    set3 = set3.prefetch(buffer_size=AUTOTUNE) \n",
        "    set4 = set4.prefetch(buffer_size=AUTOTUNE) \n",
        "    set5 = set5.prefetch(buffer_size=AUTOTUNE) \n",
        "    set6 = set6.prefetch(buffer_size=AUTOTUNE) \n",
        "    set7 = set7.prefetch(buffer_size=AUTOTUNE) \n",
        "    set8 = set8.prefetch(buffer_size=AUTOTUNE) \n",
        "    set9 = set9.prefetch(buffer_size=AUTOTUNE) \n",
        "    set10 = set10.prefetch(buffer_size=AUTOTUNE)\n",
        "    set11 = set11.prefetch(buffer_size=AUTOTUNE)\n",
        "    set12 = set12.prefetch(buffer_size=AUTOTUNE)\n",
        "    set13 = set13.prefetch(buffer_size=AUTOTUNE)\n",
        "    set14 = set14.prefetch(buffer_size=AUTOTUNE)\n",
        "    set15 = set15.prefetch(buffer_size=AUTOTUNE)\n",
        "    set16 = set16.prefetch(buffer_size=AUTOTUNE)\n",
        "    set17 = set17.prefetch(buffer_size=AUTOTUNE)\n",
        "    set18 = set18.prefetch(buffer_size=AUTOTUNE)\n",
        "    return set1,set2,set3,set4,set5,set6,set7,set8,set9,set10,set11,set12,set13,set14,set15,set16,set17,set18\n",
        "\n",
        "set1,set2,set3,set4,set5,set6,set7,set8,set9,set10,set11,set12,set13,set14,set15,set16,set17,set18 = model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2FohnCiVibU"
      },
      "source": [
        "Define function for generating logits from dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1i50PBHVgzI"
      },
      "source": [
        "def get_logits(dataset, model):\n",
        "    all_pred=tf.zeros([], tf.float64) #initialize array to hold all prediction logits (single element)\n",
        "    all_labels=tf.zeros([], tf.float64) #initialize array to hold all actual labels (single element)\n",
        "    for image_batch, label_batch in dataset.as_numpy_iterator():\n",
        "        predictions = model.predict_on_batch(image_batch).flatten() #run batch through model and return logits\n",
        "        all_pred = tf.experimental.numpy.append(all_pred, predictions)\n",
        "        all_labels = tf.experimental.numpy.append(all_labels, label_batch)\n",
        "    #tf.size(all_pred) #1335 elements, 1334 images + 1 placeholder 0 at beginning\n",
        "    all_pred = all_pred[1:]\n",
        "    all_labels = all_labels[1:]\n",
        "    return all_pred,all_labels"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8asmKVbtWqYE"
      },
      "source": [
        "all_pred, all_labels = get_logits(set1,model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8HwdbIbsYLo",
        "outputId": "55cba957-7dc6-47be-c3de-abca71890a6c"
      },
      "source": [
        "all_pred.numpy()[:5] #first five logits, of 1000"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.34710443, -0.76894206,  2.65730786, -1.82709205,  1.04971635])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2r3dNtSmNTI",
        "outputId": "2916a728-3aef-44fd-bdd3-4636202f72e0"
      },
      "source": [
        "all_pred.numpy().mean() #mean stays static for up to 7-8 digits"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.3812405023110332"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33UGFwoutRHZ",
        "outputId": "74ee7896-0fec-4034-cd93-6bdb08e1f121"
      },
      "source": [
        "all_pred.numpy().shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3plOVL_6tF-J",
        "outputId": "749cb8ff-1bc4-434a-da9b-6c1ec543e51f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_labels.numpy()[:5] #first five labels, of 1000"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1XRScfEujjO",
        "outputId": "8c8fccc6-5d6f-4807-b84b-4a755598f15b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame({'Logits':all_pred.numpy(),'Labels':all_labels.numpy()})\n",
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logits</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.347104</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.768942</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.657308</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.827092</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.049716</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Logits  Labels\n",
              "0  1.347104     0.0\n",
              "1 -0.768942     0.0\n",
              "2  2.657308     1.0\n",
              "3 -1.827092     0.0\n",
              "4  1.049716     0.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAIVq7utVQf2"
      },
      "source": [
        "df = pd.DataFrame(columns=['Logits','Labels']) #initialize dataframe\n",
        "all_sets = [set1,set2,set3,set4,set5,set6,set7,set8,set9,set10,set11,set12,set13,set14,set15,set16,set17,set18]\n",
        "for dataset in all_sets: #run for all sets:\n",
        "    all_pred, all_labels = get_logits(dataset, model)\n",
        "    df = pd.concat([df, pd.DataFrame({'Logits':all_pred.numpy(),\n",
        "                                      'Labels':all_labels.numpy()})], \n",
        "                   axis=0, ignore_index=True) #append logits & labels to dataframe"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrbxiBmq7Zop"
      },
      "source": [
        "Confirm logits and labels for all 18,000 images were saved:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JDANTPw7Qt5",
        "outputId": "9c17f149-fe74-40b8-d3c3-fccc8f4133d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wc47oZY-QM_"
      },
      "source": [
        "## **NEXT:** save logits to disk and make new file to do the same for mobilenetv2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UVlcQ7_tsD-"
      },
      "source": [
        "indiv_results_filepath = os.path.join(set1_dir, 'indiv_results.xlsx') #prep path to save to\n",
        "\n",
        "df.to_excel(indiv_results_filepath, index=False) #save to disk"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}