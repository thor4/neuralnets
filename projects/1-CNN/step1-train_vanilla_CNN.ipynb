{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Create Vanilla CNN to Classify Gabor Tilts\n",
                "--- \n",
                "## Import libraries"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
                "import matplotlib.pyplot as plt\n",
                "import os"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Create train/validate/test datasets from Gabors with a range of tilt/contrast combinations\n",
                "### The Gabors were generated in MATLAB using gen_gabor-range.m     \n",
                "- `tilts = [.1, .2, .4, .8, 1.6, 3.2]; degrees`\n",
                "- `contrasts = [.3, .45, 1];  % 30%, 45% and 100% contrast`\n",
                "## Set a batch size of 32 and resize Gabors to 160x160"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "def load_data():\n",
                "    curr_dir = os.getcwd() \n",
                "    train_dir = os.path.join(curr_dir, 'images/train_range')\n",
                "    validation_dir = os.path.join(curr_dir, 'images/validation_range')\n",
                "    test_dir = os.path.join(curr_dir, 'images/test_range')\n",
                "    BATCH_SIZE = 32 \n",
                "    IMG_SIZE = (160, 160)\n",
                "    train_dataset = image_dataset_from_directory(train_dir,\n",
                "                                             shuffle=True,\n",
                "                                             batch_size=BATCH_SIZE,\n",
                "                                             image_size=IMG_SIZE) \n",
                "    validation_dataset = image_dataset_from_directory(validation_dir,\n",
                "                                                  shuffle=True,\n",
                "                                                  batch_size=BATCH_SIZE,\n",
                "                                                  image_size=IMG_SIZE) \n",
                "    test_dataset = image_dataset_from_directory(test_dir,\n",
                "                                                  shuffle=True,\n",
                "                                                  batch_size=BATCH_SIZE,\n",
                "                                                  image_size=IMG_SIZE) \n",
                "    class_names = train_dataset.class_names #assign clockwise (clock) & counterclockwise (cclock) classes\n",
                "    return BATCH_SIZE,IMG_SIZE,train_dataset,validation_dataset,test_dataset,class_names\n",
                "\n",
                "BATCH_SIZE, IMG_SIZE, train_dataset, validation_dataset, test_dataset, class_names = load_data()"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.6 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}