{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    },
    "colab": {
      "name": "step5-test_iterations-cifar10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thor4/neuralnets/blob/master/projects/1-CNN/step5-test_iterations-cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nFaKIvYizD9"
      },
      "source": [
        "# Test Iterations\n",
        "--- \n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apuqn65zdSGP",
        "outputId": "d5463ae4-1bc2-43b2-e47d-268e2e640002"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 24 15:18:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSiAH1midWml",
        "outputId": "3b366ff1-001c-4f06-ff3e-f8d1ec27f4b4"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icB2TxuLizD_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.special import expit #import sigmoid func\n",
        "from google.colab import files\n",
        "tf.random.set_seed(42) #set random seed for reproducibility"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load and prepare the data\n",
        "---"
      ],
      "metadata": {
        "id": "0gjzdi2RN9G9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the models\n",
        "\n",
        "These models were created using the `step4_train_iterations` Jupyter notebook. Run the cell to download a zip file from OSF then extract its contents into the newly created directory.\n",
        "\n",
        "cifar10 gabors models: `content/cifar10_gabors-model_#/`\n",
        "\n",
        "where # = [0,29]"
      ],
      "metadata": {
        "id": "0eOvkcJgO8Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download + unzip models\n",
        "\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping vanilla models trained on Gabors...\")\n",
        "name = 'cifar10_gabors-models'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/e95bx/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall() #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")\n",
        "!unzip 'cifar10_gabors-model_*.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "7FL-d1C2O73N",
        "outputId": "a330885f-d85d-46e7-b29d-2928fdd9b773"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping vanilla models trained on Gabors...\n",
            "Download completed.\n",
            "Archive:  cifar10_gabors-model_17.zip\n",
            "   creating: cifar10_gabors-model_17/\n",
            "  inflating: cifar10_gabors-model_17/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_17/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_17/assets/\n",
            "   creating: cifar10_gabors-model_17/variables/\n",
            "  inflating: cifar10_gabors-model_17/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_17/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_14.zip\n",
            "   creating: cifar10_gabors-model_14/\n",
            "  inflating: cifar10_gabors-model_14/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_14/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_14/assets/\n",
            "   creating: cifar10_gabors-model_14/variables/\n",
            "  inflating: cifar10_gabors-model_14/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_14/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_7.zip\n",
            "   creating: cifar10_gabors-model_7/\n",
            "  inflating: cifar10_gabors-model_7/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_7/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_7/assets/\n",
            "   creating: cifar10_gabors-model_7/variables/\n",
            "  inflating: cifar10_gabors-model_7/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_7/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_24.zip\n",
            "   creating: cifar10_gabors-model_24/\n",
            "  inflating: cifar10_gabors-model_24/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_24/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_24/assets/\n",
            "   creating: cifar10_gabors-model_24/variables/\n",
            "  inflating: cifar10_gabors-model_24/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_24/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_19.zip\n",
            "   creating: cifar10_gabors-model_19/\n",
            "  inflating: cifar10_gabors-model_19/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_19/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_19/assets/\n",
            "   creating: cifar10_gabors-model_19/variables/\n",
            "  inflating: cifar10_gabors-model_19/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_19/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_4.zip\n",
            "   creating: cifar10_gabors-model_4/\n",
            "  inflating: cifar10_gabors-model_4/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_4/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_4/assets/\n",
            "   creating: cifar10_gabors-model_4/variables/\n",
            "  inflating: cifar10_gabors-model_4/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_4/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_13.zip\n",
            "   creating: cifar10_gabors-model_13/\n",
            "  inflating: cifar10_gabors-model_13/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_13/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_13/assets/\n",
            "   creating: cifar10_gabors-model_13/variables/\n",
            "  inflating: cifar10_gabors-model_13/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_13/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_29.zip\n",
            "   creating: cifar10_gabors-model_29/\n",
            "  inflating: cifar10_gabors-model_29/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_29/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_29/assets/\n",
            "   creating: cifar10_gabors-model_29/variables/\n",
            "  inflating: cifar10_gabors-model_29/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_29/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_22.zip\n",
            "   creating: cifar10_gabors-model_22/\n",
            "  inflating: cifar10_gabors-model_22/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_22/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_22/assets/\n",
            "   creating: cifar10_gabors-model_22/variables/\n",
            "  inflating: cifar10_gabors-model_22/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_22/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_18.zip\n",
            "   creating: cifar10_gabors-model_18/\n",
            "  inflating: cifar10_gabors-model_18/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_18/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_18/assets/\n",
            "   creating: cifar10_gabors-model_18/variables/\n",
            "  inflating: cifar10_gabors-model_18/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_18/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_0.zip\n",
            "   creating: cifar10_gabors-model_0/\n",
            "  inflating: cifar10_gabors-model_0/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_0/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_0/assets/\n",
            "   creating: cifar10_gabors-model_0/variables/\n",
            "  inflating: cifar10_gabors-model_0/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_0/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_28.zip\n",
            "   creating: cifar10_gabors-model_28/\n",
            "  inflating: cifar10_gabors-model_28/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_28/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_28/assets/\n",
            "   creating: cifar10_gabors-model_28/variables/\n",
            "  inflating: cifar10_gabors-model_28/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_28/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_27.zip\n",
            "   creating: cifar10_gabors-model_27/\n",
            "  inflating: cifar10_gabors-model_27/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_27/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_27/assets/\n",
            "   creating: cifar10_gabors-model_27/variables/\n",
            "  inflating: cifar10_gabors-model_27/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_27/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_2.zip\n",
            "   creating: cifar10_gabors-model_2/\n",
            "  inflating: cifar10_gabors-model_2/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_2/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_2/assets/\n",
            "   creating: cifar10_gabors-model_2/variables/\n",
            "  inflating: cifar10_gabors-model_2/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_2/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_8.zip\n",
            "   creating: cifar10_gabors-model_8/\n",
            "  inflating: cifar10_gabors-model_8/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_8/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_8/assets/\n",
            "   creating: cifar10_gabors-model_8/variables/\n",
            "  inflating: cifar10_gabors-model_8/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_8/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_16.zip\n",
            "   creating: cifar10_gabors-model_16/\n",
            "  inflating: cifar10_gabors-model_16/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_16/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_16/assets/\n",
            "   creating: cifar10_gabors-model_16/variables/\n",
            "  inflating: cifar10_gabors-model_16/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_16/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_6.zip\n",
            "   creating: cifar10_gabors-model_6/\n",
            "  inflating: cifar10_gabors-model_6/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_6/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_6/assets/\n",
            "   creating: cifar10_gabors-model_6/variables/\n",
            "  inflating: cifar10_gabors-model_6/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_6/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_1.zip\n",
            "   creating: cifar10_gabors-model_1/\n",
            "  inflating: cifar10_gabors-model_1/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_1/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_1/assets/\n",
            "   creating: cifar10_gabors-model_1/variables/\n",
            "  inflating: cifar10_gabors-model_1/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_1/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_10.zip\n",
            "   creating: cifar10_gabors-model_10/\n",
            "  inflating: cifar10_gabors-model_10/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_10/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_10/assets/\n",
            "   creating: cifar10_gabors-model_10/variables/\n",
            "  inflating: cifar10_gabors-model_10/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_10/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_21.zip\n",
            "   creating: cifar10_gabors-model_21/\n",
            "  inflating: cifar10_gabors-model_21/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_21/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_21/assets/\n",
            "   creating: cifar10_gabors-model_21/variables/\n",
            "  inflating: cifar10_gabors-model_21/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_21/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_12.zip\n",
            "   creating: cifar10_gabors-model_12/\n",
            "  inflating: cifar10_gabors-model_12/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_12/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_12/assets/\n",
            "   creating: cifar10_gabors-model_12/variables/\n",
            "  inflating: cifar10_gabors-model_12/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_12/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_25.zip\n",
            "   creating: cifar10_gabors-model_25/\n",
            "  inflating: cifar10_gabors-model_25/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_25/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_25/assets/\n",
            "   creating: cifar10_gabors-model_25/variables/\n",
            "  inflating: cifar10_gabors-model_25/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_25/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_5.zip\n",
            "   creating: cifar10_gabors-model_5/\n",
            "  inflating: cifar10_gabors-model_5/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_5/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_5/assets/\n",
            "   creating: cifar10_gabors-model_5/variables/\n",
            "  inflating: cifar10_gabors-model_5/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_5/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_11.zip\n",
            "   creating: cifar10_gabors-model_11/\n",
            "  inflating: cifar10_gabors-model_11/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_11/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_11/assets/\n",
            "   creating: cifar10_gabors-model_11/variables/\n",
            "  inflating: cifar10_gabors-model_11/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_11/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_3.zip\n",
            "   creating: cifar10_gabors-model_3/\n",
            "  inflating: cifar10_gabors-model_3/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_3/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_3/assets/\n",
            "   creating: cifar10_gabors-model_3/variables/\n",
            "  inflating: cifar10_gabors-model_3/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_3/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_23.zip\n",
            "   creating: cifar10_gabors-model_23/\n",
            "  inflating: cifar10_gabors-model_23/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_23/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_23/assets/\n",
            "   creating: cifar10_gabors-model_23/variables/\n",
            "  inflating: cifar10_gabors-model_23/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_23/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_26.zip\n",
            "   creating: cifar10_gabors-model_26/\n",
            "  inflating: cifar10_gabors-model_26/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_26/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_26/assets/\n",
            "   creating: cifar10_gabors-model_26/variables/\n",
            "  inflating: cifar10_gabors-model_26/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_26/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_15.zip\n",
            "   creating: cifar10_gabors-model_15/\n",
            "  inflating: cifar10_gabors-model_15/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_15/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_15/assets/\n",
            "   creating: cifar10_gabors-model_15/variables/\n",
            "  inflating: cifar10_gabors-model_15/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_15/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_20.zip\n",
            "   creating: cifar10_gabors-model_20/\n",
            "  inflating: cifar10_gabors-model_20/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_20/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_20/assets/\n",
            "   creating: cifar10_gabors-model_20/variables/\n",
            "  inflating: cifar10_gabors-model_20/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_20/variables/variables.index  \n",
            "\n",
            "Archive:  cifar10_gabors-model_9.zip\n",
            "   creating: cifar10_gabors-model_9/\n",
            "  inflating: cifar10_gabors-model_9/saved_model.pb  \n",
            "  inflating: cifar10_gabors-model_9/keras_metadata.pb  \n",
            "   creating: cifar10_gabors-model_9/assets/\n",
            "   creating: cifar10_gabors-model_9/variables/\n",
            "  inflating: cifar10_gabors-model_9/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_9/variables/variables.index  \n",
            "\n",
            "30 archives were successfully processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Delete all zip files to save space.\n",
        "dir_name = os.getcwd()\n",
        "test = os.listdir(dir_name)\n",
        "for item in test:\n",
        "    if item.endswith(\".zip\"):\n",
        "        os.remove(os.path.join(dir_name, item))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TzKpNreO0WZh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the models\n",
        "model0 = tf.keras.models.load_model('cifar10_gabors-model_0')\n",
        "model1 = tf.keras.models.load_model('cifar10_gabors-model_1')\n",
        "model2 = tf.keras.models.load_model('cifar10_gabors-model_2')\n",
        "model3 = tf.keras.models.load_model('cifar10_gabors-model_3')\n",
        "model4 = tf.keras.models.load_model('cifar10_gabors-model_4')\n",
        "model5 = tf.keras.models.load_model('cifar10_gabors-model_5')\n",
        "model6 = tf.keras.models.load_model('cifar10_gabors-model_6')\n",
        "model7 = tf.keras.models.load_model('cifar10_gabors-model_7')\n",
        "model8 = tf.keras.models.load_model('cifar10_gabors-model_8')\n",
        "model9 = tf.keras.models.load_model('cifar10_gabors-model_9')\n",
        "model10 = tf.keras.models.load_model('cifar10_gabors-model_10')\n",
        "model11 = tf.keras.models.load_model('cifar10_gabors-model_11')\n",
        "model12 = tf.keras.models.load_model('cifar10_gabors-model_12')\n",
        "model13 = tf.keras.models.load_model('cifar10_gabors-model_13')\n",
        "model14 = tf.keras.models.load_model('cifar10_gabors-model_14')\n",
        "model15 = tf.keras.models.load_model('cifar10_gabors-model_15')\n",
        "model16 = tf.keras.models.load_model('cifar10_gabors-model_16')\n",
        "model17 = tf.keras.models.load_model('cifar10_gabors-model_17')\n",
        "model18 = tf.keras.models.load_model('cifar10_gabors-model_18')\n",
        "model19 = tf.keras.models.load_model('cifar10_gabors-model_19')\n",
        "model20 = tf.keras.models.load_model('cifar10_gabors-model_20')\n",
        "model21 = tf.keras.models.load_model('cifar10_gabors-model_21')\n",
        "model22 = tf.keras.models.load_model('cifar10_gabors-model_22')\n",
        "model23 = tf.keras.models.load_model('cifar10_gabors-model_23')\n",
        "model24 = tf.keras.models.load_model('cifar10_gabors-model_24')\n",
        "model25 = tf.keras.models.load_model('cifar10_gabors-model_25')\n",
        "model26 = tf.keras.models.load_model('cifar10_gabors-model_26')\n",
        "model27 = tf.keras.models.load_model('cifar10_gabors-model_27')\n",
        "model28 = tf.keras.models.load_model('cifar10_gabors-model_28')\n",
        "model29 = tf.keras.models.load_model('cifar10_gabors-model_29')\n",
        "model0.summary() #verify architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKPIXG6dQ1yJ",
        "outputId": "ea8fd6d2-59b5-4d69-9ceb-3b1a8d04fa78"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 160, 160, 3)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 158, 158, 160)     4480      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 79, 79, 160)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 39, 39, 160)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 37, 37, 80)        115280    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 18, 18, 80)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25920)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 80)                2073680   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,194,250\n",
            "Trainable params: 810\n",
            "Non-trainable params: 2,193,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwDFLrffizEC"
      },
      "source": [
        "Download the 9 test datasets from OSF and extract the contents into the newly created directory: `content/datasets/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ss70gaYoa7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bccc7df1-12d5-49e5-aaf8-04a2a1c895d5",
        "cellView": "form"
      },
      "source": [
        "# @title Download datasets to test the model\n",
        "\n",
        "print(\"Start downloading and unzipping `9 datasets`...\")\n",
        "name = 'tilt_contrast-cifar10'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/agxyp/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall(\"datasets\") #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `9 datasets`...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all 9 training sets and use prefetch to streamline image loading."
      ],
      "metadata": {
        "id": "n_ege-imBdpK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXaUncrIizED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d949534-73a5-49c8-a82b-dd6d126c8c80",
        "cellView": "form"
      },
      "source": [
        "# @title Load datasets into tensorflow\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32 \n",
        "IMG_SIZE = (160, 160) #forces a resize from 170x170 since MobileNetV2 has weights only for certain sizes\n",
        "AUTOTUNE = tf.data.AUTOTUNE #prompts the tf.data runtime to tune the value dynamically at runtime\n",
        "def model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE):\n",
        "    curr_dir = os.getcwd() \n",
        "    set1_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_0_3')\n",
        "    set2_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_0_45')\n",
        "    set3_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_1')\n",
        "    set4_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_0_3')\n",
        "    set5_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_0_45')\n",
        "    set6_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_1')\n",
        "    set7_dir = os.path.join(curr_dir, 'datasets/t_4-c_0_3')\n",
        "    set8_dir = os.path.join(curr_dir, 'datasets/t_4-c_0_45')\n",
        "    set9_dir = os.path.join(curr_dir, 'datasets/t_4-c_1')\n",
        "    set1 = image_dataset_from_directory(set1_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE) #2000 images 2 classes\n",
        "    set2 = image_dataset_from_directory(set2_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)    \n",
        "    set3 = image_dataset_from_directory(set3_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set4 = image_dataset_from_directory(set4_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set5 = image_dataset_from_directory(set5_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set6 = image_dataset_from_directory(set6_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set7 = image_dataset_from_directory(set7_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE) \n",
        "    set8 = image_dataset_from_directory(set8_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set9 = image_dataset_from_directory(set9_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    class_names = set1.class_names #extract class names loading function inferred from subdir's\n",
        "    set1 = set1.prefetch(buffer_size=AUTOTUNE) \n",
        "    set2 = set2.prefetch(buffer_size=AUTOTUNE) \n",
        "    set3 = set3.prefetch(buffer_size=AUTOTUNE) \n",
        "    set4 = set4.prefetch(buffer_size=AUTOTUNE) \n",
        "    set5 = set5.prefetch(buffer_size=AUTOTUNE) \n",
        "    set6 = set6.prefetch(buffer_size=AUTOTUNE) \n",
        "    set7 = set7.prefetch(buffer_size=AUTOTUNE) \n",
        "    set8 = set8.prefetch(buffer_size=AUTOTUNE) \n",
        "    set9 = set9.prefetch(buffer_size=AUTOTUNE) \n",
        "    return set1,set2,set3,set4,set5,set6,set7,set8,set9,class_names\n",
        "\n",
        "set1,set2,set3,set4,set5,set6,set7,set8,set9,class_names = model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZc8G7k-Adt"
      },
      "source": [
        "There are 4,000 images per set, 2,000 per class, 36,000 total across sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9mKkQwPizEF"
      },
      "source": [
        "### 2. Generate logits\n",
        "Next, we can define a function for processing a dataset through a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66NBuNRpizEG"
      },
      "source": [
        "def process_dataset(dataset, model):\n",
        "    all_logits=tf.zeros([], tf.float64) #initialize array to hold all prediction logits (single element)\n",
        "    all_labels=tf.zeros([], tf.float64) #initialize array to hold all actual labels (single element)\n",
        "    for image_batch, label_batch in dataset.as_numpy_iterator():\n",
        "        predictions = model.predict_on_batch(image_batch).flatten() #run batch through model and return logits\n",
        "        all_logits = tf.experimental.numpy.append(all_logits, predictions)\n",
        "        all_labels = tf.experimental.numpy.append(all_labels, label_batch)\n",
        "    #tf.size(all_pred) #1335 elements, 1334 images + 1 placeholder 0 at beginning\n",
        "    all_logits = all_logits[1:]\n",
        "    all_labels = all_labels[1:]\n",
        "    all_logits_sig = expit(all_logits) #sigmoid-transform the logits\n",
        "    all_pred = np.where((all_logits_sig < 0.5), 0, 1) #replace predictions with 0 or 1\n",
        "    all_acc = np.where((all_pred == all_labels), 1, 0) #decide whether pred = label\n",
        "    return all_logits,all_labels,all_pred,all_acc"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's define a function for processing all 9 datasets through a model. In it, we will stack each sets' 4,000 logits in a single dataframe, `df_set`. The resulting dataframe will have 36,000 logits resulting from vertically stacking the logits for set1, set 2, .., set9. Additionally, we will calculate the average raw confidence and accuracy scores for each tilt/contrast combination and save this in a separate dataframe called `df_model_results`."
      ],
      "metadata": {
        "id": "YQnXLPYEUkBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_model(model,set1,set2,set3,set4,set5,set6,set7,set8,set9):\n",
        "    df_set = pd.DataFrame(columns=['Logits','Labels','Predictions','Accuracy','Tilt',\n",
        "                              'Contrast']) #init dataframe\n",
        "    df_model_results = pd.DataFrame(columns=['Accuracy','Confidence']) #init dataframe\n",
        "    all_sets = [set1,set2,set3,set4,set5,set6,set7,set8,set9]\n",
        "    all_tilts = [1.0833, 1.0833, 1.0833, 2.3958, 2.3958, 2.3958, 4, 4, 4]\n",
        "    all_contrasts = [0.3, 0.45, 1, 0.3, 0.45, 1, 0.3, 0.45, 1]\n",
        "    for idx, dataset in enumerate(all_sets): #run for all sets:\n",
        "        tilt = all_tilts[idx]\n",
        "        contrast = all_contrasts[idx]\n",
        "        all_logits,all_labels,all_pred,all_acc = process_dataset(dataset, model)\n",
        "        tilts = np.repeat(tilt, all_pred.size)\n",
        "        contrasts = np.repeat(contrast, all_pred.size)\n",
        "        df = pd.concat([df, pd.DataFrame({'Logits':all_logits.numpy(),\n",
        "                                      'Labels':all_labels.numpy(),\n",
        "                                      'Predictions':all_pred,'Accuracy':all_acc,\n",
        "                                      'Tilt':tilts,'Contrast':contrasts})], \n",
        "                  axis=0, ignore_index=True) #append logits, labels,etc to dataframe\n",
        "        acc = all_acc.mean() #calculate avg accuracy\n",
        "        conf = np.absolute(all_logits.numpy()).mean()\n",
        "        df_results = pd.concat([df_results, pd.DataFrame({'Accuracy':[acc],\n",
        "                                                'Confidence':[conf],\n",
        "                                                'Tilt':tilt,'Contrast':contrast})], \n",
        "                      axis=0, ignore_index=True) #append acc & conf to dataframe\n",
        "    return df_set,df_model_results"
      ],
      "metadata": {
        "id": "qET2WIvbU2Qg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will process all model iterations and export the resulting logits and tilt x accuracy results as excel spreadsheets."
      ],
      "metadata": {
        "id": "2mZpYyoJfpwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_models=[model0,model1,model2,model3,model4,model5,model6,model7,model8,model9,\n",
        "            model10,model11,model12,model13,model14,model15,model16,model17,model18,model19,\n",
        "            model20,model21,model22,model23,model24,model25,model26,model27,model28,model29]\n",
        "for idx, model in enumerate(all_models): #run for all models:\n",
        "  df_set,df_model_results = process_model(model,set1,set2,set3,set4,set5,set6,set7,set8,set9)\n",
        "  df_results_groupbyta = df_model_results.reset_index().set_index(['Tilt','Contrast'])\n",
        "  del df_results_groupbyta['index']\n",
        "  model_logits = \"cifar10_gabors-model_{}-logits.xlsx\".format(idx)\n",
        "  logits_excel_filepath = os.path.join(os.getcwd(), model_logits) #prep path to save to\n",
        "  df_set.to_excel(logits_excel_filepath, index=False) #save to disk\n",
        "  model_results = \"cifar10_gabors-model_{}-results.xlsx\".format(idx)\n",
        "  results_excel_filepath = os.path.join(os.getcwd(), model_results) #prep path to save to\n",
        "  df_results_groupbyta.to_excel(results_excel_filepath, index=True) #save to disk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "O7IJZH60m1UI",
        "outputId": "0e2103ec-6147-4b81-f86a-cd896fafdc6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-faffd60b2dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             model20,model21,model22,model23,model24,model25,model26,model27,model28,model29]\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#run for all models:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdf_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_model_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdf_results_groupbyta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_model_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tilt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Contrast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mdf_results_groupbyta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eed7ce6fa8f1>\u001b[0m in \u001b[0;36mprocess_model\u001b[0;34m(model, set1, set2, set3, set4, set5, set6, set7, set8, set9)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tilts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcontrast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_contrasts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mall_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtilts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtilt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcontrasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-4094c5244f71>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mall_logits_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sigmoid-transform the logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mall_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logits_sig\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#replace predictions with 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mall_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#decide whether pred = label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:Equal]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"cifar10_gabors-models-results_and_logits.zip\"  . -i \"*.xlsx\""
      ],
      "metadata": {
        "id": "yxa3yx25-1GP",
        "outputId": "3692e9c7-cb4d-4626-e839-b27805804f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: van_gabor-model_14-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_22-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_21-results.xlsx (deflated 11%)\n",
            "  adding: van_gabor-model_5-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_27-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_5-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_26-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_18-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_25-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_2-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_17-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_17-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_6-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_13-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_23-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_16-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_28-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_27-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_6-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_13-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_10-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_15-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_20-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_0-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_14-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_11-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_16-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_7-logits.xlsx (deflated 20%)\n",
            "  adding: van_gabor-model_0-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_8-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_21-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_1-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_24-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_4-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_19-logits.xlsx (deflated 19%)\n",
            "  adding: van_gabor-model_18-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_12-logits.xlsx (deflated 19%)\n",
            "  adding: van_gabor-model_10-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_23-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_29-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_26-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_24-logits.xlsx (deflated 19%)\n",
            "  adding: van_gabor-model_3-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_20-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_28-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_25-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_12-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_9-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_29-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_3-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_15-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_9-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_1-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_19-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_4-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_11-logits.xlsx (deflated 18%)\n",
            "  adding: van_gabor-model_2-logits.xlsx (deflated 19%)\n",
            "  adding: van_gabor-model_7-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_8-results.xlsx (deflated 10%)\n",
            "  adding: van_gabor-model_22-logits.xlsx (deflated 18%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"van_gabor-models-results_and_logits.zip\") #save all the results"
      ],
      "metadata": {
        "id": "V1TTkvnDAN9m",
        "outputId": "e6875918-b8a1-467b-e9d5-f262d5288206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}