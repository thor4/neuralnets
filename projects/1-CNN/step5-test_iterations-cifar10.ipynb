{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    },
    "colab": {
      "name": "step5-test_iterations-cifar10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thor4/neuralnets/blob/master/projects/1-CNN/step5-test_iterations-cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nFaKIvYizD9"
      },
      "source": [
        "# Test Iterations\n",
        "--- \n",
        "Here we will process the 9 tilt/contrast combinations for all iterations trained in step 4 and save the results to excel for visualization in step 6.\n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apuqn65zdSGP",
        "outputId": "d9a08812-c619-4677-e2ca-1a73203110f5"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 28 14:21:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSiAH1midWml",
        "outputId": "86fcc784-8f7c-4d5f-8505-c659eb85c065"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icB2TxuLizD_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from scipy.special import expit #import sigmoid func\n",
        "from google.colab import files\n",
        "tf.random.set_seed(42) #set random seed for reproducibility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load and prepare the data\n",
        "---"
      ],
      "metadata": {
        "id": "0gjzdi2RN9G9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the models\n",
        "\n",
        "These models were created using the `step4_train_iterations` Jupyter notebook. Run the cell to download a zip file from OSF then extract its contents into the newly created directory.\n",
        "\n",
        "cifar10 gabors models: `content/cifar10_gabors-model_#/`\n",
        "\n",
        "where # = [0,29]"
      ],
      "metadata": {
        "id": "0eOvkcJgO8Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download + unzip models\n",
        "\n",
        "import requests, os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "print(\"Start downloading and unzipping vanilla models trained on Gabors...\")\n",
        "name = 'cifar10_gabors-models'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/e95bx/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall() #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")\n",
        "!unzip 'cifar10_gabors-model_*.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "7FL-d1C2O73N",
        "outputId": "76874113-3fc5-4317-fe63-50de5ce0f220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping vanilla models trained on Gabors...\n",
            "Download completed.\n",
            "Archive:  cifar10_gabors-model_1.zip\n",
            "   creating: cifar10_gabors-model_1/\n",
            "  inflating: cifar10_gabors-model_1/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_1/assets/\n",
            "   creating: cifar10_gabors-model_1/variables/\n",
            "  inflating: cifar10_gabors-model_1/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_1/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_1/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_17.zip\n",
            "   creating: cifar10_gabors-model_17/\n",
            "   creating: cifar10_gabors-model_17/assets/\n",
            "  inflating: cifar10_gabors-model_17/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_17/variables/\n",
            "  inflating: cifar10_gabors-model_17/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_17/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_17/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_0.zip\n",
            "   creating: cifar10_gabors-model_0/\n",
            "  inflating: cifar10_gabors-model_0/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_0/assets/\n",
            "   creating: cifar10_gabors-model_0/variables/\n",
            "  inflating: cifar10_gabors-model_0/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_0/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_0/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_8.zip\n",
            "   creating: cifar10_gabors-model_8/\n",
            "  inflating: cifar10_gabors-model_8/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_8/assets/\n",
            "   creating: cifar10_gabors-model_8/variables/\n",
            "  inflating: cifar10_gabors-model_8/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_8/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_8/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_9.zip\n",
            "   creating: cifar10_gabors-model_9/\n",
            "  inflating: cifar10_gabors-model_9/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_9/assets/\n",
            "   creating: cifar10_gabors-model_9/variables/\n",
            "  inflating: cifar10_gabors-model_9/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_9/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_9/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_2.zip\n",
            "   creating: cifar10_gabors-model_2/\n",
            "  inflating: cifar10_gabors-model_2/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_2/assets/\n",
            "   creating: cifar10_gabors-model_2/variables/\n",
            "  inflating: cifar10_gabors-model_2/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_2/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_2/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_5.zip\n",
            "   creating: cifar10_gabors-model_5/\n",
            "  inflating: cifar10_gabors-model_5/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_5/assets/\n",
            "   creating: cifar10_gabors-model_5/variables/\n",
            "  inflating: cifar10_gabors-model_5/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_5/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_5/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_4.zip\n",
            "   creating: cifar10_gabors-model_4/\n",
            "  inflating: cifar10_gabors-model_4/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_4/assets/\n",
            "   creating: cifar10_gabors-model_4/variables/\n",
            "  inflating: cifar10_gabors-model_4/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_4/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_4/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_18.zip\n",
            "   creating: cifar10_gabors-model_18/\n",
            "   creating: cifar10_gabors-model_18/assets/\n",
            "  inflating: cifar10_gabors-model_18/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_18/variables/\n",
            "  inflating: cifar10_gabors-model_18/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_18/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_18/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_23.zip\n",
            "   creating: cifar10_gabors-model_23/\n",
            "   creating: cifar10_gabors-model_23/assets/\n",
            "  inflating: cifar10_gabors-model_23/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_23/variables/\n",
            "  inflating: cifar10_gabors-model_23/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_23/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_23/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_15.zip\n",
            "   creating: cifar10_gabors-model_15/\n",
            "   creating: cifar10_gabors-model_15/assets/\n",
            "  inflating: cifar10_gabors-model_15/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_15/variables/\n",
            "  inflating: cifar10_gabors-model_15/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_15/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_15/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_24.zip\n",
            "   creating: cifar10_gabors-model_24/\n",
            "   creating: cifar10_gabors-model_24/assets/\n",
            "  inflating: cifar10_gabors-model_24/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_24/variables/\n",
            "  inflating: cifar10_gabors-model_24/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_24/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_24/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_26.zip\n",
            "   creating: cifar10_gabors-model_26/\n",
            "   creating: cifar10_gabors-model_26/assets/\n",
            "  inflating: cifar10_gabors-model_26/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_26/variables/\n",
            "  inflating: cifar10_gabors-model_26/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_26/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_26/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_25.zip\n",
            "   creating: cifar10_gabors-model_25/\n",
            "   creating: cifar10_gabors-model_25/assets/\n",
            "  inflating: cifar10_gabors-model_25/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_25/variables/\n",
            "  inflating: cifar10_gabors-model_25/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_25/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_25/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_29.zip\n",
            "   creating: cifar10_gabors-model_29/\n",
            "   creating: cifar10_gabors-model_29/assets/\n",
            "  inflating: cifar10_gabors-model_29/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_29/variables/\n",
            "  inflating: cifar10_gabors-model_29/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_29/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_29/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_12.zip\n",
            "   creating: cifar10_gabors-model_12/\n",
            "   creating: cifar10_gabors-model_12/assets/\n",
            "  inflating: cifar10_gabors-model_12/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_12/variables/\n",
            "  inflating: cifar10_gabors-model_12/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_12/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_12/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_7.zip\n",
            "   creating: cifar10_gabors-model_7/\n",
            "  inflating: cifar10_gabors-model_7/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_7/assets/\n",
            "   creating: cifar10_gabors-model_7/variables/\n",
            "  inflating: cifar10_gabors-model_7/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_7/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_7/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_14.zip\n",
            "   creating: cifar10_gabors-model_14/\n",
            "   creating: cifar10_gabors-model_14/assets/\n",
            "  inflating: cifar10_gabors-model_14/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_14/variables/\n",
            "  inflating: cifar10_gabors-model_14/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_14/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_14/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_6.zip\n",
            "   creating: cifar10_gabors-model_6/\n",
            "  inflating: cifar10_gabors-model_6/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_6/assets/\n",
            "   creating: cifar10_gabors-model_6/variables/\n",
            "  inflating: cifar10_gabors-model_6/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_6/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_6/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_16.zip\n",
            "   creating: cifar10_gabors-model_16/\n",
            "   creating: cifar10_gabors-model_16/assets/\n",
            "  inflating: cifar10_gabors-model_16/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_16/variables/\n",
            "  inflating: cifar10_gabors-model_16/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_16/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_16/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_10.zip\n",
            "   creating: cifar10_gabors-model_10/\n",
            "   creating: cifar10_gabors-model_10/assets/\n",
            "  inflating: cifar10_gabors-model_10/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_10/variables/\n",
            "  inflating: cifar10_gabors-model_10/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_10/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_10/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_28.zip\n",
            "   creating: cifar10_gabors-model_28/\n",
            "   creating: cifar10_gabors-model_28/assets/\n",
            "  inflating: cifar10_gabors-model_28/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_28/variables/\n",
            "  inflating: cifar10_gabors-model_28/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_28/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_28/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_3.zip\n",
            "   creating: cifar10_gabors-model_31/\n",
            "   creating: cifar10_gabors-model_31/assets/\n",
            "  inflating: cifar10_gabors-model_31/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_31/variables/\n",
            "  inflating: cifar10_gabors-model_31/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_31/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_31/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_27.zip\n",
            "   creating: cifar10_gabors-model_27/\n",
            "   creating: cifar10_gabors-model_27/assets/\n",
            "  inflating: cifar10_gabors-model_27/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_27/variables/\n",
            "  inflating: cifar10_gabors-model_27/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_27/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_27/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_22.zip\n",
            "   creating: cifar10_gabors-model_22/\n",
            "   creating: cifar10_gabors-model_22/assets/\n",
            "  inflating: cifar10_gabors-model_22/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_22/variables/\n",
            "  inflating: cifar10_gabors-model_22/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_22/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_22/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_20.zip\n",
            "   creating: cifar10_gabors-model_20/\n",
            "   creating: cifar10_gabors-model_20/assets/\n",
            "  inflating: cifar10_gabors-model_20/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_20/variables/\n",
            "  inflating: cifar10_gabors-model_20/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_20/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_20/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_13.zip\n",
            "   creating: cifar10_gabors-model_13/\n",
            "   creating: cifar10_gabors-model_13/assets/\n",
            "  inflating: cifar10_gabors-model_13/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_13/variables/\n",
            "  inflating: cifar10_gabors-model_13/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_13/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_13/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_19.zip\n",
            "   creating: cifar10_gabors-model_19/\n",
            "   creating: cifar10_gabors-model_19/assets/\n",
            "  inflating: cifar10_gabors-model_19/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_19/variables/\n",
            "  inflating: cifar10_gabors-model_19/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_19/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_19/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_11.zip\n",
            "   creating: cifar10_gabors-model_32/\n",
            "   creating: cifar10_gabors-model_32/assets/\n",
            "  inflating: cifar10_gabors-model_32/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_32/variables/\n",
            "  inflating: cifar10_gabors-model_32/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_32/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_32/keras_metadata.pb  \n",
            "\n",
            "Archive:  cifar10_gabors-model_21.zip\n",
            "   creating: cifar10_gabors-model_21/\n",
            "   creating: cifar10_gabors-model_21/assets/\n",
            "  inflating: cifar10_gabors-model_21/saved_model.pb  \n",
            "   creating: cifar10_gabors-model_21/variables/\n",
            "  inflating: cifar10_gabors-model_21/variables/variables.index  \n",
            "  inflating: cifar10_gabors-model_21/variables/variables.data-00000-of-00001  \n",
            "  inflating: cifar10_gabors-model_21/keras_metadata.pb  \n",
            "\n",
            "30 archives were successfully processed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Delete all zip files to save space.\n",
        "dir_name = os.getcwd()\n",
        "test = os.listdir(dir_name)\n",
        "for item in test:\n",
        "    if item.endswith(\".zip\"):\n",
        "        os.remove(os.path.join(dir_name, item))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TzKpNreO0WZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the models\n",
        "model0 = tf.keras.models.load_model('cifar10_gabors-model_0')\n",
        "model1 = tf.keras.models.load_model('cifar10_gabors-model_1')\n",
        "model2 = tf.keras.models.load_model('cifar10_gabors-model_2')\n",
        "model3 = tf.keras.models.load_model('cifar10_gabors-model_31') #replaced chance level originals\n",
        "model4 = tf.keras.models.load_model('cifar10_gabors-model_4')\n",
        "model5 = tf.keras.models.load_model('cifar10_gabors-model_5')\n",
        "model6 = tf.keras.models.load_model('cifar10_gabors-model_6')\n",
        "model7 = tf.keras.models.load_model('cifar10_gabors-model_7')\n",
        "model8 = tf.keras.models.load_model('cifar10_gabors-model_8')\n",
        "model9 = tf.keras.models.load_model('cifar10_gabors-model_9')\n",
        "model10 = tf.keras.models.load_model('cifar10_gabors-model_10')\n",
        "model11 = tf.keras.models.load_model('cifar10_gabors-model_32') #replaced chance level originals\n",
        "model12 = tf.keras.models.load_model('cifar10_gabors-model_12')\n",
        "model13 = tf.keras.models.load_model('cifar10_gabors-model_13')\n",
        "model14 = tf.keras.models.load_model('cifar10_gabors-model_14')\n",
        "model15 = tf.keras.models.load_model('cifar10_gabors-model_15')\n",
        "model16 = tf.keras.models.load_model('cifar10_gabors-model_16')\n",
        "model17 = tf.keras.models.load_model('cifar10_gabors-model_17')\n",
        "model18 = tf.keras.models.load_model('cifar10_gabors-model_18')\n",
        "model19 = tf.keras.models.load_model('cifar10_gabors-model_19')\n",
        "model20 = tf.keras.models.load_model('cifar10_gabors-model_20')\n",
        "model21 = tf.keras.models.load_model('cifar10_gabors-model_21')\n",
        "model22 = tf.keras.models.load_model('cifar10_gabors-model_22')\n",
        "model23 = tf.keras.models.load_model('cifar10_gabors-model_23')\n",
        "model24 = tf.keras.models.load_model('cifar10_gabors-model_24')\n",
        "model25 = tf.keras.models.load_model('cifar10_gabors-model_25')\n",
        "model26 = tf.keras.models.load_model('cifar10_gabors-model_26')\n",
        "model27 = tf.keras.models.load_model('cifar10_gabors-model_27')\n",
        "model28 = tf.keras.models.load_model('cifar10_gabors-model_28')\n",
        "model29 = tf.keras.models.load_model('cifar10_gabors-model_29')\n",
        "model0.summary() #verify architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKPIXG6dQ1yJ",
        "outputId": "3e7d267b-d903-4ef5-8610-bbe5b7a87664",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, 80)                2193440   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 81        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,193,521\n",
            "Trainable params: 81\n",
            "Non-trainable params: 2,193,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwDFLrffizEC"
      },
      "source": [
        "Download the 9 test datasets from OSF and extract the contents into the newly created directory: `content/datasets/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ss70gaYoa7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798b5841-4c09-4c47-e338-9727ed07f6ac",
        "cellView": "form"
      },
      "source": [
        "# @title Download datasets to test the model\n",
        "\n",
        "print(\"Start downloading and unzipping `9 datasets`...\")\n",
        "name = 'tilt_contrast-cifar10'\n",
        "fname = f\"{name}.zip\"\n",
        "url = f\"https://osf.io/agxyp/download\" #osf share link\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "with open(fname, 'wb') as fh:\n",
        "  fh.write(r.content) #download file\n",
        "\n",
        "with ZipFile(fname, 'r') as zfile:\n",
        "  zfile.extractall(\"datasets\") #extract contents\n",
        "\n",
        "if os.path.exists(fname):\n",
        "  os.remove(fname) #delete zip file\n",
        "else:\n",
        "  print(f\"The file {fname} does not exist\")\n",
        "\n",
        "print(\"Download completed.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start downloading and unzipping `9 datasets`...\n",
            "Download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all 9 training sets and use prefetch to streamline image loading."
      ],
      "metadata": {
        "id": "n_ege-imBdpK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXaUncrIizED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af12810-c97b-459e-cf5a-1e9e47447443",
        "cellView": "form"
      },
      "source": [
        "# @title Load datasets into tensorflow\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "BATCH_SIZE = 32 \n",
        "IMG_SIZE = (160, 160) #forces a resize from 170x170 since MobileNetV2 has weights only for certain sizes\n",
        "AUTOTUNE = tf.data.AUTOTUNE #prompts the tf.data runtime to tune the value dynamically at runtime\n",
        "def model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE):\n",
        "    curr_dir = os.getcwd() \n",
        "    set1_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_0_3')\n",
        "    set2_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_0_45')\n",
        "    set3_dir = os.path.join(curr_dir, 'datasets/t_1_0833-c_1')\n",
        "    set4_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_0_3')\n",
        "    set5_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_0_45')\n",
        "    set6_dir = os.path.join(curr_dir, 'datasets/t_2_3958-c_1')\n",
        "    set7_dir = os.path.join(curr_dir, 'datasets/t_4-c_0_3')\n",
        "    set8_dir = os.path.join(curr_dir, 'datasets/t_4-c_0_45')\n",
        "    set9_dir = os.path.join(curr_dir, 'datasets/t_4-c_1')\n",
        "    set1 = image_dataset_from_directory(set1_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE) #2000 images 2 classes\n",
        "    set2 = image_dataset_from_directory(set2_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)    \n",
        "    set3 = image_dataset_from_directory(set3_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set4 = image_dataset_from_directory(set4_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set5 = image_dataset_from_directory(set5_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set6 = image_dataset_from_directory(set6_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set7 = image_dataset_from_directory(set7_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE) \n",
        "    set8 = image_dataset_from_directory(set8_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    set9 = image_dataset_from_directory(set9_dir, shuffle=False, batch_size=BATCH_SIZE, image_size=IMG_SIZE)\n",
        "    class_names = set1.class_names #extract class names loading function inferred from subdir's\n",
        "    set1 = set1.prefetch(buffer_size=AUTOTUNE) \n",
        "    set2 = set2.prefetch(buffer_size=AUTOTUNE) \n",
        "    set3 = set3.prefetch(buffer_size=AUTOTUNE) \n",
        "    set4 = set4.prefetch(buffer_size=AUTOTUNE) \n",
        "    set5 = set5.prefetch(buffer_size=AUTOTUNE) \n",
        "    set6 = set6.prefetch(buffer_size=AUTOTUNE) \n",
        "    set7 = set7.prefetch(buffer_size=AUTOTUNE) \n",
        "    set8 = set8.prefetch(buffer_size=AUTOTUNE) \n",
        "    set9 = set9.prefetch(buffer_size=AUTOTUNE) \n",
        "    return set1,set2,set3,set4,set5,set6,set7,set8,set9,class_names\n",
        "\n",
        "set1,set2,set3,set4,set5,set6,set7,set8,set9,class_names = model2_init_sets(BATCH_SIZE, IMG_SIZE, AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n",
            "Found 4000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuZc8G7k-Adt"
      },
      "source": [
        "There are 4,000 images per set, 2,000 per class, 36,000 total across sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9mKkQwPizEF"
      },
      "source": [
        "### 2. Generate logits\n",
        "Next, we can define a function for processing a dataset through a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66NBuNRpizEG"
      },
      "source": [
        "def process_dataset(dataset, model):\n",
        "    all_logits=tf.zeros([], tf.float64) #initialize array to hold all prediction logits (single element)\n",
        "    all_labels=tf.zeros([], tf.float64) #initialize array to hold all actual labels (single element)\n",
        "    for image_batch, label_batch in dataset.as_numpy_iterator():\n",
        "        predictions = model.predict_on_batch(image_batch).flatten() #run batch through model and return logits\n",
        "        all_logits = tf.experimental.numpy.append(all_logits, predictions)\n",
        "        all_labels = tf.experimental.numpy.append(all_labels, label_batch)\n",
        "    #tf.size(all_pred) #1335 elements, 1334 images + 1 placeholder 0 at beginning\n",
        "    all_logits = all_logits[1:]\n",
        "    all_labels = all_labels[1:]\n",
        "    all_logits_sig = expit(all_logits) #sigmoid-transform the logits\n",
        "    all_pred = np.where((all_logits_sig < 0.5), 0, 1) #replace predictions with 0 or 1\n",
        "    all_acc = np.where((all_pred == all_labels), 1, 0) #decide whether pred = label\n",
        "    return all_logits,all_labels,all_pred,all_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's define a function for processing all 9 datasets through a model. In it, we will stack each sets' 4,000 logits in a single dataframe, `df_set`. The resulting dataframe will have 36,000 logits resulting from vertically stacking the logits for set1, set 2, .., set9. Additionally, we will calculate the average raw confidence and accuracy scores for each tilt/contrast combination and save this in a separate dataframe called `df_model_results`."
      ],
      "metadata": {
        "id": "YQnXLPYEUkBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_model(model,set1,set2,set3,set4,set5,set6,set7,set8,set9):\n",
        "    df_set = pd.DataFrame(columns=['Logits','Labels','Predictions','Accuracy','Tilt',\n",
        "                              'Contrast']) #init dataframe\n",
        "    df_model_results = pd.DataFrame(columns=['Accuracy','Confidence']) #init dataframe\n",
        "    all_sets = [set1,set2,set3,set4,set5,set6,set7,set8,set9]\n",
        "    all_tilts = [1.0833, 1.0833, 1.0833, 2.3958, 2.3958, 2.3958, 4, 4, 4]\n",
        "    all_contrasts = [0.3, 0.45, 1, 0.3, 0.45, 1, 0.3, 0.45, 1]\n",
        "    for idx, dataset in enumerate(all_sets): #run for all sets:\n",
        "        tilt = all_tilts[idx]\n",
        "        contrast = all_contrasts[idx]\n",
        "        all_logits,all_labels,all_pred,all_acc = process_dataset(dataset, model)\n",
        "        tilts = np.repeat(tilt, all_pred.size)\n",
        "        contrasts = np.repeat(contrast, all_pred.size)\n",
        "        df_set = pd.concat([df_set, pd.DataFrame({'Logits':all_logits.numpy(),\n",
        "                                      'Labels':all_labels.numpy(),\n",
        "                                      'Predictions':all_pred,'Accuracy':all_acc,\n",
        "                                      'Tilt':tilts,'Contrast':contrasts})], \n",
        "                  axis=0, ignore_index=True) #append logits, labels,etc to dataframe\n",
        "        acc = all_acc.mean() #calculate avg accuracy\n",
        "        conf = np.absolute(all_logits.numpy()).mean()\n",
        "        df_model_results = pd.concat([df_model_results, pd.DataFrame({'Accuracy':[acc],\n",
        "                                                'Confidence':[conf],\n",
        "                                                'Tilt':tilt,'Contrast':contrast})], \n",
        "                      axis=0, ignore_index=True) #append acc & conf to dataframe\n",
        "    return df_set,df_model_results"
      ],
      "metadata": {
        "id": "qET2WIvbU2Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will process all model iterations and export the resulting logits and tilt x accuracy results as excel spreadsheets."
      ],
      "metadata": {
        "id": "2mZpYyoJfpwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_models=[model0,model1,model2,model3,model4,model5,model6,model7,model8,model9,\n",
        "            model10,model11,model12,model13,model14,model15,model16,model17,model18,model19,\n",
        "            model20,model21,model22,model23,model24,model25,model26,model27,model28,model29]\n",
        "for idx, model in enumerate(all_models): #run for all models:\n",
        "  df_set,df_model_results = process_model(model,set1,set2,set3,set4,set5,set6,set7,set8,set9)\n",
        "  df_results_groupbyta = df_model_results.reset_index().set_index(['Tilt','Contrast'])\n",
        "  del df_results_groupbyta['index']\n",
        "  model_logits = \"cifar10_gabors-model_{}-logits.xlsx\".format(idx)\n",
        "  logits_excel_filepath = os.path.join(os.getcwd(), model_logits) #prep path to save to\n",
        "  df_set.to_excel(logits_excel_filepath, index=False) #save to disk\n",
        "  model_results = \"cifar10_gabors-model_{}-results.xlsx\".format(idx)\n",
        "  results_excel_filepath = os.path.join(os.getcwd(), model_results) #prep path to save to\n",
        "  df_results_groupbyta.to_excel(results_excel_filepath, index=True) #save to disk"
      ],
      "metadata": {
        "id": "O7IJZH60m1UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"cifar10_gabors-models-results_and_logits.zip\"  . -i \"*.xlsx\""
      ],
      "metadata": {
        "id": "yxa3yx25-1GP",
        "outputId": "7529eb4e-6c70-4841-cef9-89a788e5bebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: cifar10_gabors-model_11-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_19-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_23-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_9-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_10-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_8-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_17-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_1-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_0-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_24-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_29-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_13-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_21-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_4-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_3-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_19-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_25-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_27-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_1-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_26-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_14-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_7-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_7-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_15-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_5-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_18-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_6-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_26-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_21-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_15-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_2-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_17-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_16-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_3-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_9-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_2-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_13-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_5-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_22-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_29-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_22-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_18-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_10-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_0-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_11-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_25-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_24-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_27-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_4-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_6-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_12-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_12-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_23-logits.xlsx (deflated 20%)\n",
            "  adding: cifar10_gabors-model_8-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_28-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_28-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_16-logits.xlsx (deflated 19%)\n",
            "  adding: cifar10_gabors-model_14-results.xlsx (deflated 11%)\n",
            "  adding: cifar10_gabors-model_20-results.xlsx (deflated 10%)\n",
            "  adding: cifar10_gabors-model_20-logits.xlsx (deflated 20%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"cifar10_gabors-models-results_and_logits.zip\") #save all the results"
      ],
      "metadata": {
        "id": "V1TTkvnDAN9m",
        "outputId": "b3311c15-4f5c-4397-c30e-450d3c9ba46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6ff9f282-d8bb-4392-98d5-a66d2c121f5e\", \"cifar10_gabors-models-results_and_logits.zip\", 27469222)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}