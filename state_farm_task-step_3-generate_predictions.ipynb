{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHYNDCU8wZOGcPLocilAII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thor4/neuralnets/blob/master/state_farm_task-step_3-generate_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State Farm Pre-employment Assessment\n",
        "### *Model-based supervised learning binary classification task*\n",
        "Your work will be evaluated in the following areas:\n",
        "- The appropriateness of the steps you took\n",
        "- The complexity of your models\n",
        "- The performance of each model on the test set (using AUC)\n",
        "- The organization and readability of your code\n",
        "- The write-up comparing the models\n",
        "---"
      ],
      "metadata": {
        "id": "3I9U6tnpuecf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Generate predictions\n",
        "Create predictions on the data in test.csv using each of your trained models. The predictions should be the class probabilities for belonging to the positive class (labeled '1').  \n",
        " \n",
        "Be sure to output a prediction for each of the rows in the test dataset (10K rows). Save the results of each of your models in a separate CSV file.  Title the two files 'glmresults.csv' and 'nonglmresults.csv'. Each file should have a single column representing the predicted probabilities for its respective model. Please do not include a header label or index column.\n",
        "\n",
        "We will begin by importing relevant libraries."
      ],
      "metadata": {
        "id": "FKKVf2XCvo5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zct-rkSSud0m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer, QuantileTransformer, LabelEncoder\n",
        "import joblib\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the saved models from the GitHub repository."
      ],
      "metadata": {
        "id": "bvl1wLl1Ul5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/thor4/neuralnets/blob/master/projects/state_farm/models/logistic_regression_model.pkl\n",
        "!wget https://github.com/thor4/neuralnets/blob/master/projects/state_farm/models/grid_search_gb_model.pkl"
      ],
      "metadata": {
        "id": "R98SybX6Uo6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use the pandas library to load our CSV data and joblib to load our models."
      ],
      "metadata": {
        "id": "gHKnysvV1TZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"exercise_40_test.csv\")\n",
        "logistic_regression = joblib.load('logistic_regression_model.pkl')\n",
        "grid_search_gb = joblib.load('grid_search_gb_model.pkl')"
      ],
      "metadata": {
        "id": "lsLMUhbm1Z2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "ly3yQCem28eQ",
        "outputId": "a6f88610-3639-458f-bb43-21bb628a7fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   y        x1         x2        x3        x4        x5        x6        x7  \\\n",
              "0  0  0.165254  18.060003       Wed  1.077380 -1.339233 -1.584341   0.0062%   \n",
              "1  1  2.441471  18.416307    Friday  1.482586  0.920817 -0.759931   0.0064%   \n",
              "2  1  4.427278  19.188092  Thursday  0.145652  0.366093  0.709962   -8e-04%   \n",
              "3  0  3.925235  19.901257   Tuesday  1.763602 -0.251926 -0.827461  -0.0057%   \n",
              "4  0  2.868802  22.202473    Sunday  3.405119  0.083162  1.381504   0.0109%   \n",
              "\n",
              "         x8        x9  ...       x91       x92  x93       x94       x95  \\\n",
              "0  0.220784  1.816481  ... -0.397427  0.909479   no  5.492487       NaN   \n",
              "1  1.192441  3.513950  ...  0.656651  9.093466   no  3.346429  4.321172   \n",
              "2  0.952323  0.782974  ...  2.059615  0.305170   no  4.456565       NaN   \n",
              "3 -0.520756  1.825586  ...  0.899392  5.971782   no  4.100022  1.151085   \n",
              "4 -0.732739  2.151990  ...  3.003595  1.046096  yes  3.234033  2.074927   \n",
              "\n",
              "         x96        x97  x98  x99        x100  \n",
              "0  10.255579   7.627730    0  yes  104.251338  \n",
              "1        NaN  10.505284    1  yes  101.230645  \n",
              "2   8.754572   7.810979    0  yes  109.345215  \n",
              "3        NaN   9.178325    1  yes  103.021970  \n",
              "4   9.987006  11.702664    0  yes   92.925935  \n",
              "\n",
              "[5 rows x 101 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9236d1b8-b099-44bc-adfd-d0fac45eb18b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>...</th>\n",
              "      <th>x91</th>\n",
              "      <th>x92</th>\n",
              "      <th>x93</th>\n",
              "      <th>x94</th>\n",
              "      <th>x95</th>\n",
              "      <th>x96</th>\n",
              "      <th>x97</th>\n",
              "      <th>x98</th>\n",
              "      <th>x99</th>\n",
              "      <th>x100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.165254</td>\n",
              "      <td>18.060003</td>\n",
              "      <td>Wed</td>\n",
              "      <td>1.077380</td>\n",
              "      <td>-1.339233</td>\n",
              "      <td>-1.584341</td>\n",
              "      <td>0.0062%</td>\n",
              "      <td>0.220784</td>\n",
              "      <td>1.816481</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.397427</td>\n",
              "      <td>0.909479</td>\n",
              "      <td>no</td>\n",
              "      <td>5.492487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.255579</td>\n",
              "      <td>7.627730</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>104.251338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2.441471</td>\n",
              "      <td>18.416307</td>\n",
              "      <td>Friday</td>\n",
              "      <td>1.482586</td>\n",
              "      <td>0.920817</td>\n",
              "      <td>-0.759931</td>\n",
              "      <td>0.0064%</td>\n",
              "      <td>1.192441</td>\n",
              "      <td>3.513950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.656651</td>\n",
              "      <td>9.093466</td>\n",
              "      <td>no</td>\n",
              "      <td>3.346429</td>\n",
              "      <td>4.321172</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.505284</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>101.230645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>4.427278</td>\n",
              "      <td>19.188092</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>0.145652</td>\n",
              "      <td>0.366093</td>\n",
              "      <td>0.709962</td>\n",
              "      <td>-8e-04%</td>\n",
              "      <td>0.952323</td>\n",
              "      <td>0.782974</td>\n",
              "      <td>...</td>\n",
              "      <td>2.059615</td>\n",
              "      <td>0.305170</td>\n",
              "      <td>no</td>\n",
              "      <td>4.456565</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.754572</td>\n",
              "      <td>7.810979</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>109.345215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.925235</td>\n",
              "      <td>19.901257</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>1.763602</td>\n",
              "      <td>-0.251926</td>\n",
              "      <td>-0.827461</td>\n",
              "      <td>-0.0057%</td>\n",
              "      <td>-0.520756</td>\n",
              "      <td>1.825586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.899392</td>\n",
              "      <td>5.971782</td>\n",
              "      <td>no</td>\n",
              "      <td>4.100022</td>\n",
              "      <td>1.151085</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.178325</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>103.021970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2.868802</td>\n",
              "      <td>22.202473</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>3.405119</td>\n",
              "      <td>0.083162</td>\n",
              "      <td>1.381504</td>\n",
              "      <td>0.0109%</td>\n",
              "      <td>-0.732739</td>\n",
              "      <td>2.151990</td>\n",
              "      <td>...</td>\n",
              "      <td>3.003595</td>\n",
              "      <td>1.046096</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.234033</td>\n",
              "      <td>2.074927</td>\n",
              "      <td>9.987006</td>\n",
              "      <td>11.702664</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>92.925935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9236d1b8-b099-44bc-adfd-d0fac45eb18b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9236d1b8-b099-44bc-adfd-d0fac45eb18b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9236d1b8-b099-44bc-adfd-d0fac45eb18b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "cBh11z0idZAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the test dataset for pre-processing."
      ],
      "metadata": {
        "id": "_VwiMCdtdxrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test_data.copy()"
      ],
      "metadata": {
        "id": "2WHpvZb_diIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop unnecessary columns"
      ],
      "metadata": {
        "id": "wcV3RRn4UozQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.drop(columns=[\"x39\", \"x99\", \"x79\", \"x28\"])"
      ],
      "metadata": {
        "id": "nfMPlZFrUeRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert object columns to binary int64\n"
      ],
      "metadata": {
        "id": "EU2q5JQ4Us9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_features = [\"x24\", \"x31\", \"x93\"]\n",
        "for col in binary_features:\n",
        "    le = LabelEncoder()\n",
        "    test[col] = le.fit_transform(test[col].astype(str))"
      ],
      "metadata": {
        "id": "aAcIdOJMUvBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace null values in `x33` and `x77` with most likely value based on probabilities"
      ],
      "metadata": {
        "id": "TUmDVBO-U-Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"x33\", \"x77\"]:\n",
        "    probs = test[col].value_counts(normalize=True)\n",
        "    missing = test[col].isna()\n",
        "    test.loc[missing, col] = np.random.choice(probs.index, size=len(test[missing]), p=probs.values)"
      ],
      "metadata": {
        "id": "Yz6UiUDHU82J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine duplicate days in `x3`"
      ],
      "metadata": {
        "id": "ePxMKLv8V-oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_mapping = {\n",
        "    \"Mon\": \"Monday\",\n",
        "    \"Tue\": \"Tuesday\",\n",
        "    \"Wed\": \"Wednesday\",\n",
        "    \"Thur\": \"Thursday\",\n",
        "    \"Fri\": \"Friday\",\n",
        "    \"Sat\": \"Saturday\",\n",
        "    \"Sun\": \"Sunday\"\n",
        "}\n",
        "test[\"x3\"] = test[\"x3\"].replace(day_mapping)"
      ],
      "metadata": {
        "id": "ntj_wWcfV4_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the `x7` column to a float by removing the % sign and dividing by 100. Convert the `x19` column to a float by removing the $ sign."
      ],
      "metadata": {
        "id": "YGROjnzlNsTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['x7'] = test['x7'].str.strip('%').astype(float) / 100\n",
        "test['x19'] = test['x19'].str.strip('$').astype(float)"
      ],
      "metadata": {
        "id": "fgF_31UUKmYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run preprocessing pipeline"
      ],
      "metadata": {
        "id": "uCETwZrId_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformers for each group of columns\n",
        "one_hot_features = [\"x33\", \"x77\", \"x3\", \"x60\", \"x65\"]\n",
        "range_based_features = [\"x58\", \"x67\", \"x71\", \"x84\"]\n",
        "quantile_transform_features = [\"x12\", \"x18\", \"x61\", \"x92\", \"x40\", \"x57\"]\n",
        "log_transform_features = [\"x14\", \"x16\", \"x21\", \"x42\", \"x45\", \"x55\", \"x70\", \"x73\", \"x75\", \"x82\", \"x89\", \"x96\"]\n",
        "\n",
        "one_hot_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"one_hot\", OneHotEncoder())\n",
        "])\n",
        "\n",
        "def custom_discretizer(X, low_quantile=0.25, high_quantile=0.75):\n",
        "    low_bound = np.quantile(X, low_quantile, axis=0)\n",
        "    high_bound = np.quantile(X, high_quantile, axis=0)\n",
        "    return np.where(X < low_bound, 0, np.where(X <= high_bound, 1, 2))\n",
        "\n",
        "range_based_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"custom_discretizer\", FunctionTransformer(custom_discretizer, validate=True)),\n",
        "    (\"one_hot\", OneHotEncoder())\n",
        "])\n",
        "\n",
        "quantile_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"quantile_transform\", QuantileTransformer(output_distribution=\"normal\"))\n",
        "])\n",
        "\n",
        "def log1p_with_positive_shift(X):\n",
        "    positive_shift = np.abs(np.min(X, axis=0)) + 1e-6\n",
        "    return np.log1p(X + positive_shift)\n",
        "\n",
        "log_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"log_transform\", FunctionTransformer(log1p_with_positive_shift, validate=True)),\n",
        "    (\"standard_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "remaining_float_features = list(set(train.select_dtypes(include=[\"float64\"]).columns) - set(range_based_features) - set(quantile_transform_features) - set(log_transform_features))\n",
        "\n",
        "float_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"standard_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Create ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"one_hot\", one_hot_transformer, one_hot_features),\n",
        "    (\"range_based\", range_based_transformer, range_based_features),\n",
        "    (\"quantile_transform\", quantile_transformer, quantile_transform_features),\n",
        "    (\"log_transform\", log_transformer, log_transform_features),\n",
        "    (\"float_transform\", float_transformer, remaining_float_features)\n",
        "])\n",
        "\n",
        "# Apply the preprocessing pipeline\n",
        "X_transformed = preprocessor.fit_transform(test)\n",
        "\n",
        "# Get the column names from the transformers\n",
        "one_hot_cols = preprocessor.named_transformers_[\"one_hot\"].named_steps[\"one_hot\"].get_feature_names_out(one_hot_features)\n",
        "range_based_categories = [\"low\", \"middle\", \"high\"]\n",
        "range_based_cols = [f\"{col}_{cat}\" for col in range_based_features for cat in range_based_categories]\n",
        "quantile_transform_cols = [f\"quantile_{col}\" for col in quantile_transform_features]\n",
        "log_transform_cols = [f\"log_{col}\" for col in log_transform_features]\n",
        "float_transform_cols = [f\"float_{col}\" for col in remaining_float_features]\n",
        "\n",
        "print(\"One-hot cols:\", len(one_hot_cols))\n",
        "print(\"Range-based cols:\", len(range_based_cols))\n",
        "print(\"Quantile transform cols:\", len(quantile_transform_cols))\n",
        "print(\"Log transform cols:\", len(log_transform_cols))\n",
        "print(\"Float transform cols:\", len(float_transform_cols))\n",
        "\n",
        "# Combine column names\n",
        "columns = (list(one_hot_cols)\n",
        "           + list(range_based_cols)\n",
        "           + quantile_transform_cols\n",
        "           + log_transform_cols\n",
        "           + float_transform_cols)\n",
        "\n",
        "print(\"Total expected columns:\", len(columns))\n",
        "print(\"Actual columns in transformed dataset:\", X_transformed.shape[1])\n",
        "\n",
        "test_transformed = pd.DataFrame(X_transformed, columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4J-NlNLUASG",
        "outputId": "54da0660-434a-48b5-93d4-af351068cd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot cols: 82\n",
            "Range-based cols: 12\n",
            "Quantile transform cols: 6\n",
            "Log transform cols: 12\n",
            "Float transform cols: 64\n",
            "Total expected columns: 176\n",
            "Actual columns in transformed dataset: 176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transformed.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqG700y9O7tU",
        "outputId": "5d7dd048-04da-4e93-be15-e4f47947a9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40000 entries, 0 to 39999\n",
            "Columns: 176 entries, x33_Alabama to float_x41\n",
            "dtypes: float64(176)\n",
            "memory usage: 53.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transformed.columns[test_transformed.isnull().sum() != 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roiZtwsTPBtb",
        "outputId": "d4504679-1948-4056-fe6a-94307bd5f4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and save predictions"
      ],
      "metadata": {
        "id": "0mvT3SK9YiE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate predictions (class probabilities) for both models."
      ],
      "metadata": {
        "id": "b482ZWisXt0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_prob = logistic_regression.predict_proba(X_transformed)[:, 1]\n",
        "grid_search_gb_prob = grid_search_gb.predict_proba(X_transformed)[:, 1]"
      ],
      "metadata": {
        "id": "7oI6lA00XusZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the predictions in two separate CSV files."
      ],
      "metadata": {
        "id": "Khr7UsZsYBjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save logistic_regression predictions to glmresults.csv\n",
        "pd.DataFrame(logistic_regression_prob).to_csv('glmresults.csv', header=False, index=False)\n",
        "\n",
        "# Save grid_search_gb predictions to nonglmresults.csv\n",
        "pd.DataFrame(grid_search_gb_prob).to_csv('nonglmresults.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "nkLE9q-hYDM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the files for submission."
      ],
      "metadata": {
        "id": "wSOsqHqYYRhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('glmresults.csv')\n",
        "files.download('nonglmresults.csv')"
      ],
      "metadata": {
        "id": "T0bnUdPzYKHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}